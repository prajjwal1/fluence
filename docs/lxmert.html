---

title: LXMERT

keywords: fastai
sidebar: home_sidebar

summary: "Implements LXMERT model"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: lxmert.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
    {% raw %}
        
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>I0219 22:46:20.413658 140479127459648 file_utils.py:35] PyTorch version 1.4.0+cpu available.
/glob/intel-python/python3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.
  _np_qint8 = np.dtype([(&#34;qint8&#34;, np.int8, 1)])
/glob/intel-python/python3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.
  _np_quint8 = np.dtype([(&#34;quint8&#34;, np.uint8, 1)])
/glob/intel-python/python3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.
  _np_qint16 = np.dtype([(&#34;qint16&#34;, np.int16, 1)])
/glob/intel-python/python3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.
  _np_quint16 = np.dtype([(&#34;quint16&#34;, np.uint16, 1)])
/glob/intel-python/python3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.
  _np_qint32 = np.dtype([(&#34;qint32&#34;, np.int32, 1)])
/glob/intel-python/python3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or &#39;1type&#39; as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / &#39;(1,)type&#39;.
  np_resource = np.dtype([(&#34;resource&#34;, np.ubyte, 1)])
/glob/intel-python/python3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="GeLU" class="doc_header"><code>class</code> <code>GeLU</code><a href="https://github.com/prajjwal1/fluence/tree/master/fluence/models/lxmert/lxmert.py#L26" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>GeLU</code>() :: <code>Module</code></p>
</blockquote>
<p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>

<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))

</code></pre>
<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:<code>to</code>, etc.</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="BertEmbeddings" class="doc_header"><code>class</code> <code>BertEmbeddings</code><a href="https://github.com/prajjwal1/fluence/tree/master/fluence/models/lxmert/lxmert.py#L33" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>BertEmbeddings</code>(<strong><code>config</code></strong>) :: <code>Module</code></p>
</blockquote>
<p>Construct the embeddings from word, position and token_type embeddings.</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="BertAttention" class="doc_header"><code>class</code> <code>BertAttention</code><a href="https://github.com/prajjwal1/fluence/tree/master/fluence/models/lxmert/lxmert.py#L63" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>BertAttention</code>(<strong><code>config</code></strong>, <strong><code>params</code></strong>) :: <code>Module</code></p>
</blockquote>
<p>Usage:
    from transformers import BertConfig
    bert_att = BertAttention(BertConfig())
    context_output = bert_att(hidden_states = torch.rand(128,20,768),
                              context = torch.rand(128,36,768),
                            attention_mask = None)
    context_output.shape # [128, 20, 768]</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="BertAttOutput" class="doc_header"><code>class</code> <code>BertAttOutput</code><a href="https://github.com/prajjwal1/fluence/tree/master/fluence/models/lxmert/lxmert.py#L145" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>BertAttOutput</code>(<strong><code>config</code></strong>) :: <code>Module</code></p>
</blockquote>
<p>Usage:
    from transformers import BertConfig
    bert_att_output = BertAttOutput(BertConfig())
    output = bert_att_output(torch.rand(128,20,768),torch.rand(128,20,768))
    output.shape [128,20,768]</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="k">import</span> <span class="n">BertConfig</span>
<span class="n">bert_att_output</span> <span class="o">=</span> <span class="n">BertAttOutput</span><span class="p">(</span><span class="n">BertConfig</span><span class="p">())</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">bert_att_output</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span><span class="mi">20</span><span class="p">,</span><span class="mi">768</span><span class="p">),</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span><span class="mi">20</span><span class="p">,</span><span class="mi">768</span><span class="p">))</span>
<span class="k">assert</span> <span class="n">output</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">128</span><span class="p">,</span><span class="mi">20</span><span class="p">,</span><span class="mi">768</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="BertCrossattLayer" class="doc_header"><code>class</code> <code>BertCrossattLayer</code><a href="https://github.com/prajjwal1/fluence/tree/master/fluence/models/lxmert/lxmert.py#L166" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>BertCrossattLayer</code>(<strong><code>config</code></strong>, <strong><code>params</code></strong>) :: <code>Module</code></p>
</blockquote>
<p>from transformers import BertConfig</p>
<p>bert_cross_att = BertCrossattLayer(BertConfig())
output = bert_cross_att(input_tensor = torch.rand(128,20,768),
                    ctx_tensor = torch.rand(128,36,768),
                    ctx_att_mask = None)</p>
<p>output.shape [128,20,768]</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="BertSelfattLayer" class="doc_header"><code>class</code> <code>BertSelfattLayer</code><a href="https://github.com/prajjwal1/fluence/tree/master/fluence/models/lxmert/lxmert.py#L188" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>BertSelfattLayer</code>(<strong><code>config</code></strong>, <strong><code>params</code></strong>) :: <code>Module</code></p>
</blockquote>
<p>bert_self_att_layer = BertSelfattLayer(bert_config)
output = bert_self_att_layer(input_tensor = torch.rand(128,20,768),
                         attention_mask = torch.rand(128,1,1,20))
output.shape [128, 20, 768]</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="BertIntermediate" class="doc_header"><code>class</code> <code>BertIntermediate</code><a href="https://github.com/prajjwal1/fluence/tree/master/fluence/models/lxmert/lxmert.py#L207" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>BertIntermediate</code>(<strong><code>config</code></strong>) :: <code>Module</code></p>
</blockquote>
<p>bert_intermediate = BertIntermediate(bert_config)
output = bert_intermediate(torch.rand(128,20,768))
output.shape # [128,20,3072]</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="BertOutput" class="doc_header"><code>class</code> <code>BertOutput</code><a href="https://github.com/prajjwal1/fluence/tree/master/fluence/models/lxmert/lxmert.py#L228" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>BertOutput</code>(<strong><code>config</code></strong>) :: <code>Module</code></p>
</blockquote>
<p>bert_output = BertOutput(bert_config)
output = bert_output(hidden_states = torch.rand(128,20,3072),
                     input_tensor = torch.rand(128,20,768))
output.shape # [128,20,768]</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="BertLayer" class="doc_header"><code>class</code> <code>BertLayer</code><a href="https://github.com/prajjwal1/fluence/tree/master/fluence/models/lxmert/lxmert.py#L249" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>BertLayer</code>(<strong><code>config</code></strong>, <strong><code>params</code></strong>) :: <code>Module</code></p>
</blockquote>
<p>from transformers import BertConfig
bert_layer  = BertLayer(BertConfig())
output = bert_layer(torch.rand(128,20,768),torch.rand(128,1,1,20))
output.shape [128,20,768]</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="k">import</span> <span class="n">BertConfig</span>
<span class="n">bert_layer</span>  <span class="o">=</span> <span class="n">BertLayer</span><span class="p">(</span><span class="n">BertConfig</span><span class="p">(),</span> <span class="n">params</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">bert_layer</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span><span class="mi">20</span><span class="p">,</span><span class="mi">768</span><span class="p">),</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">20</span><span class="p">))</span>
<span class="k">assert</span> <span class="n">output</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">128</span><span class="p">,</span><span class="mi">20</span><span class="p">,</span><span class="mi">768</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="LXRTXLayer" class="doc_header"><code>class</code> <code>LXRTXLayer</code><a href="https://github.com/prajjwal1/fluence/tree/master/fluence/models/lxmert/lxmert.py#L269" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>LXRTXLayer</code>(<strong><code>config</code></strong>, <strong><code>params</code></strong>) :: <code>Module</code></p>
</blockquote>
<p>from transformers import BertConfig
lxrtx_layer = LXRTXLayer(BertConfig())
output = lxrtx_layer(lang_feats = torch.rand(128,20,768),
                  lang_attention_mask = torch.rand(128,1,1,20),
                  visn_feats = torch.rand(128,36,768),
                  visn_attention_mask = None)</p>
<p>lang_output.shape: [128,20,768]
visn_output.shape: [128,36,768]</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="VisualFeatEncoder" class="doc_header"><code>class</code> <code>VisualFeatEncoder</code><a href="https://github.com/prajjwal1/fluence/tree/master/fluence/models/lxmert/lxmert.py#L334" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>VisualFeatEncoder</code>(<strong><code>config</code></strong>) :: <code>Module</code></p>
</blockquote>
<p>from transformers import BertConfig</p>
<p>visual_feat_encoder = VisualFeatEncoder(BertConfig())
output = visual_feat_encoder((torch.rand(128,36,2048),torch.rand(128,36,4))) # img_feats+box_feats</p>
<p>output.shape: [128,36,768]</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="LXRTEncoder" class="doc_header"><code>class</code> <code>LXRTEncoder</code><a href="https://github.com/prajjwal1/fluence/tree/master/fluence/models/lxmert/lxmert.py#L372" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>LXRTEncoder</code>(<strong><code>config</code></strong>, <strong><code>params</code></strong>) :: <code>Module</code></p>
</blockquote>
<p>from transformers import BertConfig
lxrt_encoder = LXRTEncoder(BertConfig())</p>
<p>lang_output, visn_output = lxrt_encoder(lang_feats = torch.rand(128,20,768),
                                        lang_attention_mask = torch.rand(128,1,1,20),
                                        visn_feats = (torch.rand(128,36,2048),torch.rand(128,36,4)),
                                        visn_attention_mask = None)</p>
<p>lang_feats.shape: [128,20,768]
visn_feats.shape: [128,36,768]</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="BertPooler" class="doc_header"><code>class</code> <code>BertPooler</code><a href="https://github.com/prajjwal1/fluence/tree/master/fluence/models/lxmert/lxmert.py#L444" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>BertPooler</code>(<strong><code>config</code></strong>) :: <code>Module</code></p>
</blockquote>
<p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>

<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))

</code></pre>
<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:<code>to</code>, etc.</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="LXRTModel" class="doc_header"><code>class</code> <code>LXRTModel</code><a href="https://github.com/prajjwal1/fluence/tree/master/fluence/models/lxmert/lxmert.py#L457" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>LXRTModel</code>(<strong><code>config</code></strong>, <strong><code>params</code></strong>) :: <a href="/fluence/lxmert_utils#BertPreTrainedModel"><code>BertPreTrainedModel</code></a></p>
</blockquote>
<p>LXRT Model.</p>
<p>model = LXRTModel.from_pretrained("bert-base-uncased")</p>
<p>output = model(input_ids = torch.rand(128,20).long(),
           token_type_ids = torch.rand(128,20).long(),
           attention_mask = torch.rand(128,32).long(),
           visual_feats = (torch.rand(128,36,2048),torch.rand(128,36,4)),
           visual_attention_mask = None)</p>
<p>lang_feats.shape -&gt; [128, 20, 768]
vision_feats.shape -&gt; [128, 36, 768]
pooled_output.shape -&gt; [128,768]</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="VisualBertForLXRFeature" class="doc_header"><code>class</code> <code>VisualBertForLXRFeature</code><a href="https://github.com/prajjwal1/fluence/tree/master/fluence/models/lxmert/lxmert.py#L524" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>VisualBertForLXRFeature</code>(<strong><code>config</code></strong>, <strong><code>params</code></strong>, <strong><code>mode</code></strong>=<em><code>'lxr'</code></em>) :: <a href="/fluence/lxmert_utils#BertPreTrainedModel"><code>BertPreTrainedModel</code></a></p>
</blockquote>
<p>BERT model for classification.</p>
<p>bert = VisualBertForLXRFeature.from_pretrained("bert-base-uncased",mode='x')</p>
<p>output = bert(input_ids = torch.rand(128,20).long(),
          token_type_ids = torch.rand(128,20).long(),
          attention_mask = torch.rand(128,20).long(),
          visual_feats = (torch.rand(128,36,2048),torch.rand(128,36,4)), # for feats and boxes
          visual_attention_mask = None)</p>
<p>output.shape -&gt; [128,768]          ,</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="LXRTEncoder_" class="doc_header"><code>class</code> <code>LXRTEncoder_</code><a href="https://github.com/prajjwal1/fluence/tree/master/fluence/models/lxmert/lxmert.py#L561" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>LXRTEncoder_</code>(<strong><code>params</code></strong>, <strong><code>mode</code></strong>=<em><code>'x'</code></em>) :: <code>Module</code></p>
</blockquote>
<p>Usage:
    Input:
        lxrt_encoder = LXRTEncoder(args,MAX_VQA_LENGTH=20).cuda()
        feat = torch.rand(128,36,2048).cuda()
        pos = torch.rand(128,36,4).cuda()
        sent = list(sentences) # len(sent) = batch_size i.e 128</p>

<pre><code>Output:
    output = lxrt_encoder(sent, (feat.cuda(), pos.cuda())) # [128,768]</code></pre>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="LXMERT_Adaptive" class="doc_header"><code>class</code> <code>LXMERT_Adaptive</code><a href="https://github.com/prajjwal1/fluence/tree/master/fluence/models/lxmert/lxmert.py#L649" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>LXMERT_Adaptive</code>(<strong><code>num_answers</code></strong>, <strong><code>params</code></strong>) :: <code>Module</code></p>
</blockquote>
<p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>

<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))

</code></pre>
<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:<code>to</code>, etc.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}
</div>
 

